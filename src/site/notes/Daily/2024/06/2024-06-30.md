---
{"dg-publish":true,"permalink":"/daily/2024/06/2024-06-30/","noteIcon":"📝","created":"2024-06-30T19:11:48.405+07:00","updated":"2024-07-13T15:35:31.921+07:00"}
---


## **1. Giới thiệu và Mục tiêu**

### a. Giới thiệu

- Ở thời điểm hiện tại, các Mô hình ngôn ngữ lớn (LLM) đã đạt được những đột phá lớn, ví dụ như Sora [^1] của OpenAI có thể tạo video từ văn bản, hay ChatGPT-4 [^2] có thể giải được những bài toán Olympiad, viết code, ...
- Thế nhưng những tác vụ mà mô hình giải quyết chỉ được đánh giá trên các tập dữ liệu mà có thông tin liên quan đến các tác vụ ấy, điều này không có tính thực tế. Do đó chúng ta cần đánh giá trên một tập dữ liệu mà có thêm vào các thông tin không liên quan đến các tác vụ ấy, trong bài báo này, nhóm tác giả sẽ nghiên cứu các thông tin không liên quan có làm mô hình bị *bối rối* (distractability) hay làm giảm độ chính xác của mô hình.
- Cụ thể hơn, nhóm tác giả sử dụng bộ dữ liệu GSM-IC (Grade-School Math with Irrelavant Context), một bộ dữ liệu dùng để đánh giá khả năng giải toán của mô hình có kèm các thông tin không liên quan. Bộ dữ liệu này được xây dựng từ bộ dữ liệu GSM8K [^3]. Nhóm tác giả cũng đưa ra hai độ đo khác nhau để đánh giá độ chính xác của mô hình trên tập dữ liệu này. Khác với nghiên cứu[^4] [^5], thay vì thay các câu thành câu mới ở bộ dữ liệu gốc GSM8K, nhóm tác giả sẽ giữ nguyên các câu ở bộ dữ liệu gốc và thêm vào một câu không liên quan với mục đích là giữ nguyên lời giải ở dữ liệu gốc.
- Ngoài ra nhóm tác giả cũng sử dụng bộ dữ liệu này để đánh giá các kĩ thuật prompt. Cuối cùng, nhóm tác giả đưa ra các cách tiếp cận để giảm thiểu sự bối rối này bao gồm việc thêm kĩ thuật self-consistency hay thêm vào prompt hướng dẫn mô hình bỏ qua các câu không liên quan.
### b. Mục tiêu

> Viết mục tiêu ở đây
## **2. Phương pháp nghiên cứu**

### a. Sử dụng mô hình

- Nhóm tác giả sử dụng hai mô hình là  `code-davinci-002` và `text-davinci-003`. Thế nhưng ở thời điểm hiện tại (tháng 7 năm 2024) thì hai mô hình này đã bị dừng hoạt động bởi OpenAI và thay thế bằng mô hình `gpt-3.5 turbo` [^6].
- Về cơ bản thì mô hình `code-davinci-002` và `text-davinci-003` đều xuất phát từ một mô hình gốc là `GPT-3`. Sau đó `GPT-3` sẽ được huấn luyện trên dữ liệu gồm code và kết hợp với instruction tuning (tức là mô hình sẽ được fine-tune lại trên một tập dữ liêu có nhãn, mỗi prompt sẽ bao gồm hướng dẫn để tạo ra output mong muốn [^7]) để tạo ra `code-davinci-002`.
- Tiếp sau đó, `code-davinci-002` sẽ trải qua 2 giai đoạn là supervised instruction tuning (như trên) và RLHF [^8] để tạo ra được `text-davinci-003`.

Các mô hình của OpenAI (nguồn [^9]). ![Pasted image 20240713103023.png](/img/user/Attachment/Pasted%20image%2020240713103023.png)

- Sở dĩ việc tác giả chọn 2 mô hình này là vì đây là hai mô hình lớn và tốt nhất thời điểm bấy giờ (tầm năm 2022 - 2023). Ngoài ra thì `code-davinci-002` cũng là mô hình đạt được SoTA trên bộ dữ liệu GMS8K (tại thời điểm ấy).
- Còn ở thời điểm hiện tại, do 2 mô hình này đã bị ngừng hoạt động nên các lựa chọn khác có thể kể đến là `GPT-3.5 Turbo` hay `Claude`, ...
### b. Tạo dataset

> Viết dataset ở đây
### c. Các kĩ thuật Prompting

Để cho đơn giản và tránh việc over-fitting, tất cả kĩ thuật prompt đều sử dụng chung 1 dữ liệu (hay là 1 bài toán) duy nhất. Bài toán này có thể được lấy từ bài toán gốc (gọi là [Orginal Problem]) (trong GSM8K) hay là bài toán ấy nhưng thêm thông tin không liên quan (gọi là [Problem with Irrelevant Context]) (trong GSM-IC).

Sau đó các kĩ thuật Prompt sẽ dựa trên [Original Problem] hoặc [Problem with Irrelavant Context] để tạo ra các prompt kết hợp với [Problem of Interest] (đây là bài toán mà ta muốn mô hình đưa ra lời giải).

Các kĩ thuật Prompting được tác giả sử dụng bao gồm:
- **Chain-of-Thought Prompting** [^10] (hay còn gọi là CoT): Ở kĩ thuật, ta sẽ hướng dẫn mô hình giải quyết bài toán bằng cách chỉ ra từng bước để giải quyết bài toán ấy. Kĩ thuật này được áp dụng trong bài báo này như sau: Ta sẽ lấy [Original Problem], đưa ra từng bước để giải quyết [Original Problem] ấy (gọi là [CoT Solution]), cuối cùng là thêm [Problem of Interest] và mong mô hình sẽ giải quyết được [Problem of Interest] bằng các bước giải ta đưa ra trong prompt.

![Pasted image 20240713125212.png](/img/user/Attachment/Pasted%20image%2020240713125212.png)
- **Zero-shot chain-of-thought prompting** [^11] (hay còn gọi là 0-CoT):  Ở kĩ thuật này, tác giả sẽ đưa ra luôn [Problem of Interest] và thêm câu *"Let’s think step by step"*. Khi đó nhóm tác giả cũng mong muốn kĩ thuật này cho độ chính xác tương tự CoT (thay vì đưa ra từng bước thì ta bảo rằng mô hình sẽ tự đưa ra từng bước giải bài toán ấy).

![Pasted image 20240713130041.png](/img/user/Attachment/Pasted%20image%2020240713130041.png)
- **Least-to-most prompting** [^12]: Ở kĩ thuật này, ta sẽ tách [Original Problem] thành các bài toán con đơn giản hơn, sau đó dùng CoT, tức là sẽ đưa ra từng bước giải cho các bài toán con ấy. Cuối cùng là thêm câu *"Let's break down this problem"*.

![Pasted image 20240713130635.png](/img/user/Attachment/Pasted%20image%2020240713130635.png)
- **Program prompts** [^13]: Ở kĩ thuật này, thay vì dùng chữ để đưa ra từng bước giải, ta sẽ thể hiện các bước giải cho bài toán ấy bằng code (ở trong bài báo này là code Python).

![Pasted image 20240713132343.png](/img/user/Attachment/Pasted%20image%2020240713132343.png)
- **Self-consistency** [^14]: Kĩ thuật này không phải là một kỹ thuật dùng riêng mà sẽ được kết hợp với các kĩ thuật prompting phía trên để tăng độ chính xác. Ở kĩ thuật này, tác giả sẽ tạo ra nhiều prompt, mỗi prompt sẽ giải quyết bài toán bằng một cách khác nhau, các prompt này có thể được tạo ra bằng cách dùng các kĩ thuật bên trên hoặc không dùng. Sau đó ta sẽ đưa prompt này cho model và thực hiện nhiều lần, sau đó chọn kết quả mà xuất hiện nhiều nhất trong các lần thử. Trong bài báo [^15] của nhóm tác giả, nhóm tác giả sử dụng self-consistency khoảng 20 lần và có kết luận trong 20 lần ấy, luôn có ít nhất 1 lần kết quả đúng, vì vậy nếu sử dụng prompt nhiều lần gần như chắc chắn mô hình sẽ đưa ra câu trả lời đúng.

Các câu prompt mà tác giả sử dụng (nguồn: [^15]) 
![Pasted image 20240713130112.png](/img/user/Attachment/Pasted%20image%2020240713130112.png)

So sánh giữa prompt thường và CoT prompt (nguồn [^13]). ![Pasted image 20240713132114.png](/img/user/Attachment/Pasted%20image%2020240713132114.png)

Kĩ thuật cuối cùng chính là **Instructed Prompting**. Ở kĩ thuật này, trước mỗi prompt, nhóm tác giả sẽ thêm vào câu *"Solve grade school math problems. Feel free to ignore irrelevant information given in the questions"*, câu này sẽ bảo rằng mô hình bỏ qua các thông tin không liên quan trong bài toán.

![Pasted image 20240713153448.png](/img/user/Attachment/Pasted%20image%2020240713153448.png)
### d. Accuracy

> Viết accuracy ở đây

[^1]: https://openai.com/index/sora/
[^2]: https://arxiv.org/abs/2303.08774
[^3]: https://arxiv.org/pdf/2110.14168
[^4]: https://aclanthology.org/2021.naacl-main.168.pdf
[^5]: https://aclanthology.org/2021.findings-emnlp.230.pdf
[^6]: https://platform.openai.com/docs/deprecations
[^7]: https://www.ibm.com/topics/instruction-tuning
[^8]: https://huggingface.co/blog/rlhf
[^9]: https://yaofu.notion.site/How-does-GPT-Obtain-its-Ability-Tracing-Emergent-Abilities-of-Language-Models-to-their-Sources-b9a57ac0fcf74f30a1ab9e3e36fa1dc1
[^10]: https://openreview.net/pdf?id=_VjQlMeSB_J
[^11]: https://arxiv.org/abs/2205.11916
[^12]: https://arxiv.org/abs/2205.10625
[^13]: https://arxiv.org/pdf/2204.02311
[^14]: https://arxiv.org/abs/2203.11171
[^15]: https://arxiv.org/pdf/2302.00093